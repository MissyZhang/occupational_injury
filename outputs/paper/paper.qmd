---
title: "Trends in Work-related Injury Frequency Rate in Canada"
subtitle: "Maritime operations have experienced a notable decline, contributing to an overall downward trend "
author: Missy Zhang
thanks: "Code and data are available at: [https://github.com/MissyZhang/occupational_injury](https://github.com/MissyZhang/occupational_injury)."
date: "`r Sys.time()`"
date-format: "D MMMM YYYY"
abstract: "This paper aims to examine the work-related injury frequency rate in Canada over the past 12 years. To explore whether and how injury rate has declined in Canada, this paper aims to investigate the relationship between time, industry, and work-related injury frequency rate in Canada. Using Statistics Canada data, it was found that there was an overall downward trend in the frequency of injuries over time, with the decline most pronounced in maritime operations. Particularly, it is closely related to the proportion of outdoor workers in the industry. In addition, this paper shares insights into injury prevention strategies for Canadian workplaces, and highlights the industries and worker populations that may be most vulnerable to workplace injuries. "
format: pdf
number-sections: true
bibliography: references.bib
execute: 
  message: false
  warning: false
  echo: false

---

```{r}
#| include: false


library(tidyverse)
library(tinytex)
library(modelsummary)
library(kableExtra)
library(dplyr)

# Read inputs
cleaned_data <- read_csv(here::here("inputs/data/cleaned_data.csv"))

```


# Introduction

In recent years, work-related injuries have emerged as a critical issue in Canada, affecting workers across various industries. These injuries can have devastating physical and psychological impacts on workers and can also result in a significant economic burden on society. Despite a decrease in the number of injuries in recent years, there were still 37,024 work-related injuries reported in 2020 alone [@cite1]. To address this issue and improve workplace safety, it is crucial to understand injury trends over time and across different sectors. This report aims to analyze work-related injury data and explore factors that contribute to work-related injuries. By identifying areas that require improvement and highlighting successful initiatives, this report aims to contribute to the ongoing efforts to create safer workplaces and reduce the incidence of work-related injuries.

This report utilizes data of injury statistics in Canada by industry sector from 2008 to 2020 obtained from the Open Government Data of Statistics Canada [@citeSC] and used programming language R [@citeR] to build models and analyze trends. The estimand of this report is work-related injury frequency rate, which is measured by injuries (disabling, fatal and minor) per one million hours worked. This paper delves into the overall trend of injury frequency rate in Canada by industry using multiple linear regression model. It was found that there was an overall downward trend in the frequency of injuries over time, with the decline most pronounced in maritime operations. Particularly, it is closely related to the proportion of outdoor workers in the industry. 


The remainder of the paper is split into four sections. In @sec-data, the cleaned dataset is explored to identify key variables of interest, namely the year, industry, and injury frequency rate. Visualizations in the form of tables and figures are presented to illustrate potential correlations between these variables. Before constructing the multiple linear regression model in @sec-model, it is observed through data visualization that the injury frequency rate in Canada has generally decreased over time, albeit with variations across different industries. The final model is interpreted and findings on the evolution of injury frequency rate are presented in @sec-results. In @sec-discussion, the implications of these findings on time and industry are discussed, along with potential federal and provincial-level solutions and limitations of this study.



# Data {#sec-data}


```{r}
#| label: fig-year
#| fig-cap: Work-related injury frequency rate by year in Canada from 2008 to 2020
cleaned_data %>%
  filter(Industry == "CANADA") %>%
  ggplot(aes(x= Year, y= injury_frequency_rate)) +
  geom_line(color = "blue")+
  theme_minimal()+
  ylab("Injury Frequency Rate") +
  scale_x_continuous(breaks = seq(2000, 2020, 2),  
                     labels = seq(2000, 2020, 2))
```


```{r}
#| label: fig-byin
#| fig-cap: Work-related injury frequency rate by year and industry in Canada from 2008 to 2020
#| fig-width: 12
#| fig-height: 5

cleaned_data %>%
  filter(Industry != "CANADA") %>%
  ggplot(aes(x=Year, y=injury_frequency_rate, colour = Industry)) +
  geom_point() +
  theme_minimal() +
  ylab("Injury Frequency Rate") +
  scale_x_continuous(breaks = seq(2000, 2020, 2),  
                     labels = seq(2000, 2020, 2))



```


\newpage

# Model {#sec-model}

```{r}
#| include: false
library(tidymodels)
set.seed(1130)

# split the data into training and testing sets
injury_model <- cleaned_data %>%
  filter(Industry != "CANADA")

injury_model_split <- initial_split(data = injury_model, prop = 0.80)

injury_model_train <- training(injury_model_split)
injury_model_test <- testing(injury_model_split)


# construct multiple linear regression model 1 with the training set
model1 <- lm(injury_frequency_rate~Industry+Year, data = injury_model_train)

# construct multiple linear regression model 2 with the training set
model2 <- lm(injury_frequency_rate~Industry + Year + Industry*Year, data = injury_model_train)


```


$$
Y_{ij} = \beta_{0}+\beta_{1}Year_{i}+\beta_{2}Industry_{j}+\beta_{3}Year_{i}Industry_{j} 
$$ {#eq-bayes}

In Model @eq-bayes:

- $Y_{ij}$ is the injury frequency rate in $i^{th}$ year and industry $j$.
- $\beta_{0}$ is the coefficient for intercept.
- $\beta_{1}$ is the coefficient for the continuous year variable.
- $\beta_{2}$ is the coefficient corresponding to industry $j$.
- $\beta_{3}$ is the coefficient for the interaction term between $i^{th}$ year and industry $j$.
- The baseline of this model is year 0 and Air Transportation industry.

\newpage

# Results {#sec-results}

```{r}
#| label: fig-billssssss
#| fig-cap: More bills of penguins
#| echo: false
#| fig-width: 12
#| fig-height: 6

cleaned_data %>%
  filter(Industry != "CANADA") %>%
  ggplot(aes(x=Year, y=injury_frequency_rate, colour = Industry))+
  geom_point()+
  theme_minimal()+
  ylab("Injury Frequency Rate")+
  geom_smooth(method='lm')+
  scale_x_continuous(breaks = seq(2000, 2020, 2),  
                     labels = seq(2000, 2020, 2))



```



```{r}
# summarize the value and confidence interval of the coefficients in a table
coef_summary <- summary(model2)$coefficients
confint_summary <- confint(model2)

row_names <- c("Intercept", "Banking/Banks", "Broadcasting (Television, Radio, Internet)", "Communications", "Crown Corporations", "Energy/Mining/Mineral Processing", "Federal Public Services/Public Service Departments/Crown Corporations ", "Feed, Flour and Seed", "Grain Handling/Grain Elevators", "Indigenous", "Interprovincial Infrastructure (Bridges, Tunnels, Canals, Causeways)", "Long shoring/Stevedoring/Port/Harbour Operations/Pilotage", "Pipeline Transportation", "Postal Services/Postal Contractors", "Public Service Departments", "Rail Transportation", "Road Transportation", "Water Transportation (Shipping and Ferries)", "Year" ,"Year: Banking/Banks", "Year: Broadcasting (Television, Radio, Internet)", "Year: Communications", "Year: Crown Corporations", "Year: Energy/Mining/Mineral Processing", "Year: Federal Public Services/Public Service Departments/Crown Corporations ", "Year: Feed, Flour and Seed", "Year: Grain Handling/Grain Elevators", "Year: Indigenous", "Year: Interprovincial Infrastructure (Bridges, Tunnels, Canals, Causeways)", "Year: Long shoring/Stevedoring/Port/Harbour Operations/Pilotage", "Year: Pipeline Transportation", "Year: Postal Services/Postal Contractors", "Year: Public Service Departments", "Year: Rail Transportation", "Year: Road Transportation", "Year: Water Transportation (Shipping and Ferries)")


rownames(coef_summary) <- row_names
rownames(confint_summary) <- row_names


# create a table of coefficient summaries
summary_table <- tibble(
  Name =row.names(coef_summary), 
  Coefficients = coef_summary[,1],
  `95% Confidence Interval Lower Bound` = confint_summary[,1],
  `95% Confidence Interval Upper Bound` = confint_summary[,2]
)[1:length(coef_summary[,1]),] # use the same length as the Coefficients column




```




```{r}
# display the summarized table
summary_table %>%
  kable(
    caption = "Model Coefficients and 95 percent Confidence Interval",
col.names=c(" ", "Coefficients", "Confidence Interval Lower Bound", "Confidence Interval Upper Bound"),
linesep = "", digits = 1, booktabs=TRUE) %>%
  kable_styling(latex_options = "HOLD_position", font_size = 8) %>%
  column_spec(1, width = "18em") %>%
  column_spec(2, width = "6em") %>%
  column_spec(3, width = "12em") %>%
  column_spec(4, width = "12em")
  
```



\newpage

# Discussion {#sec-discussion}

## First discussion point 


## Second discussion point

## Third discussion point

## Weaknesses and next steps



\newpage

\appendix

# Appendix 

# Model Testing

R package "modelsummary"[@citemodelsummary] helps to display the coefficients of the two models as well as the result of a series of tests to compare which model performs better.

$R^2$ measures how well the model explains its response variable's variation. If $R^2$ is low, it indicates that the model doesn't fit the data well. By @table-test, in Model 1, 84.5% of the variability is explained, and in Model 2, 87.4% of the variability is explained. Both models demonstrate a pretty high $R^2$ value.

AIC and BIC measure the prediction ability of the multiple linear regression model. AIC (Akaikeâ€™s Information Criteria) focuses on how well the model fits unknown data, while BIC (Bayesian Information Criteria) focuses on the true model and favours simpler models [@citeAIC]. Lower AIC and BIC both indicate that the model has better prediction power. By @table-test, Model 2 has slightly lower AIC and BIC than Model 1, implying that Model 2 has more prediction power.

```{r}
modelsummary(list("Model 1" = model1, 
                  "Model 2" = model2), 
             fmt = 2,
             title = "Comparing Model 1 and Model 2's Statistics",
             output = "markdown")

```

\newpage

```{r}

# predict based on testing dataset
pred1 <- predict(model1, newdata = injury_model_test)
pred2 <- predict(model2, newdata = injury_model_test)

error1 <- injury_model_test$injury_frequency_rate - pred1
error2 <- injury_model_test$injury_frequency_rate - pred2

RMSE1 <- sqrt(mean(error1^2))
RMSE2 <- sqrt(mean(error2^2))

```

```{r}
#| label: table3
table_RMSE <- tibble(dataset = c("train","test"),
                     `Model 1` = c(10.95, 15.89),
                     `Model 2` = c(6.66, 9.29))


table_RMSE %>%
  kable(
    caption = "Comparing RMSE between two models",
col.names=c("Dataset", "Model 1", "Model 2" ),
linesep = "", digits = 1, booktabs=TRUE) %>%
  kable_styling(latex_options = "HOLD_position", font_size = 10)
```



The RMSE measures how far the predicted values of the multiple linear regression model are from their actual values on average. The lower the RMSE, the better the model preforms regarding prediction. Based on @table3, the RMSE for both two models are very similar for training and testing dataset, indicating that the dataset is unbiased and the two models are performing as expected. Moreover, Model 2 has lower RMSE than Model 1 for both training and testing dataset, indicating that Model 2 predicts data more accurately.


\newpage

# Model Assumption Check

```{r}
#| fig-width: 6
#| fig-height: 5
#| label: figure3
# plot the model to check for its assumptions
par(mfrow = c(2, 2))
plot(model2)
```


Check for assumptions:
Assumptions to the multiple linear regression model are checked to ensure that the model is valid for this dataset. @figure3 shows the plots used to check for the assumption.

The Residuals vs Fitted plot checks for the linear relationship assumption. Since the red line is almost horizontal and there isn't any pattern, the model satisfies the linearity assumption. The Normal QQ plot checks for the residual normality assumption. Since almost all the dots are on the dashed line, the residuals follow a normal distribution. The Scale-Location plot checks for the homoscedasticity assumption. The red line is horizontal, and the dots are evenly scattered, indicating that the variance of the residuals is constant [@citecheck]. 

\newpage


\newpage


# References


